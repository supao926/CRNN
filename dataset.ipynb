{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c0203c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnibabel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnib\u001b[39;00m  \u001b[38;5;66;03m# 處理 .nii 檔案的標準庫\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import nibabel as nib  # 處理 .nii 檔案的標準庫\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CRNNDataset(Dataset):\n",
    "    def __init__(self, root_dir, target_dir, n_frames=3, is_train=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (str): 存放 Training Data (原圖 .nii) 的資料夾\n",
    "            target_dir (str): 存放 Label Data (標註 .nii) 的資料夾\n",
    "            n_frames (int): 輸入模型的連續幀數 (e.g. 3)\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.target_dir = target_dir\n",
    "        self.n_frames = n_frames\n",
    "        self.is_train = is_train\n",
    "        \n",
    "        # 建立索引：這是關鍵，我們不直接存圖片，而是存「去哪裡找這張圖」的清單\n",
    "        self.samples = self._make_dataset()\n",
    "\n",
    "    def _make_dataset(self):\n",
    "        \"\"\"\n",
    "        掃描資料夾，讀取每個 NIfTI 的 header (不讀內容)，\n",
    "        計算有多少個切片，並建立索引表。\n",
    "        \"\"\"\n",
    "        samples = []\n",
    "        \n",
    "        # 1. 搜尋所有 .nii 或 .nii.gz 檔案\n",
    "        if not os.path.exists(self.root_dir):\n",
    "             raise ValueError(f\"Directory not found: {self.root_dir}\")\n",
    "             \n",
    "        file_names = sorted([f for f in os.listdir(self.root_dir) \n",
    "                             if f.endswith(('.nii', '.nii.gz'))])\n",
    "        \n",
    "        print(f\"Found {len(file_names)} NIfTI files in {self.root_dir}\")\n",
    "\n",
    "        for fname in file_names:\n",
    "            img_path = os.path.join(self.root_dir, fname)\n",
    "            lbl_path = os.path.join(self.target_dir, fname) # 假設檔名完全一致\n",
    "            \n",
    "            # 檢查 Label 是否存在\n",
    "            if not os.path.exists(lbl_path):\n",
    "                print(f\"[Warning] Label not found for {fname}, skipping...\")\n",
    "                continue\n",
    "            \n",
    "            # 2. 讀取 Header 獲取切片數量 (Depth)\n",
    "            # nib.load 不會把整個檔案讀進 RAM，只讀 Header，非常快\n",
    "            proxy_img = nib.load(img_path)\n",
    "            n_slices = proxy_img.shape[2]\n",
    "            \n",
    "            # 3. 製作滑動視窗索引\n",
    "            # 假設 n_frames=3，我們從第 0 張開始，直到 n_slices - n_frames + 1\n",
    "            if n_slices >= self.n_frames:\n",
    "                for i in range(n_slices - self.n_frames + 1):\n",
    "                    samples.append({\n",
    "                        'img_path': img_path,\n",
    "                        'lbl_path': lbl_path,\n",
    "                        'start_idx': i  # 這是視窗的第一幀索引\n",
    "                    })\n",
    "        \n",
    "        print(f\"Total samples (slices) created: {len(samples)}\")\n",
    "        return samples\n",
    "\n",
    "    def _load_nii_slice(self, path, slice_idx):\n",
    "        \"\"\"\n",
    "        讀取單一 NIfTI 檔案中的特定切片。\n",
    "        使用 dataobj 進行 Disk-IO 讀取，避免載入整個 3D 體積。\n",
    "        \"\"\"\n",
    "        img_obj = nib.load(path)\n",
    "        \n",
    "        # dataobj 是 ArrayProxy，支援 slicing，只讀取需要的這層\n",
    "        # 這裡還沒有做 Normalization，拿到的是原始 HU 值\n",
    "        slice_data = img_obj.dataobj[..., slice_idx]\n",
    "        \n",
    "        # 轉為 float32 以便後續運算\n",
    "        slice_data = np.array(slice_data, dtype=np.float32)\n",
    "        \n",
    "        # NIfTI 讀出來通常這時候還不需要轉置，視你的模型習慣\n",
    "        # PyTorch 習慣 (C, H, W)，這裡我們先回傳 (H, W)\n",
    "        return slice_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample_info = self.samples[idx]\n",
    "        img_path = sample_info['img_path']\n",
    "        lbl_path = sample_info['lbl_path']\n",
    "        start_idx = sample_info['start_idx']\n",
    "        \n",
    "        # --- 1. Load Input Volumes (連續 n_frames 張) ---\n",
    "        tensors = []\n",
    "        for i in range(self.n_frames):\n",
    "            curr_slice_idx = start_idx + i\n",
    "            \n",
    "            # 讀取原始 HU 值 (下一步驟我們再來加 Windowing & CLAHE)\n",
    "            img_slice = self._load_nii_slice(img_path, curr_slice_idx)\n",
    "            \n",
    "            # [暫時] 先簡單轉成 Tensor 讓我們能測試跑通\n",
    "            # 之後這裡會插入 _preprocess(img_slice)\n",
    "            tensor = torch.from_numpy(img_slice).unsqueeze(0) # (1, H, W)\n",
    "            tensors.append(tensor)\n",
    "            \n",
    "        # 整理 input (prev, curr, next)\n",
    "        sample = {}\n",
    "        if self.n_frames == 3:\n",
    "            sample = {'prev': tensors[0], 'curr': tensors[1], 'next': tensors[2]}\n",
    "        elif self.n_frames == 2:\n",
    "            sample = {'prev': tensors[0], 'curr': tensors[1]}\n",
    "\n",
    "        # --- 2. Load Label (只取中間那幀) ---\n",
    "        # 如果是 3 幀，Label 對應中間 (index + 1)\n",
    "        # 如果是 2 幀，Label 對應後面 (index + 1)\n",
    "        lbl_slice_idx = start_idx + 1\n",
    "        \n",
    "        raw_mask = self._load_nii_slice(lbl_path, lbl_slice_idx)\n",
    "        \n",
    "        # === 核心邏輯：只取 Label == 5 ===\n",
    "        # 製作 Binary Mask: 5 -> 1.0, 其他 -> 0.0\n",
    "        mask = (raw_mask == 5).astype(np.float32)\n",
    "        \n",
    "        # 轉 Tensor: (1, H, W)\n",
    "        sample['label'] = torch.from_numpy(mask).unsqueeze(0)\n",
    "            \n",
    "        return sample\n",
    "\n",
    "    def _preprocess(self, img_np):\n",
    "            \"\"\"\n",
    "            輸入: Raw Slice (float32), 包含原始 HU 值\n",
    "            輸出: Tensor (8, H, W)\n",
    "            \"\"\"\n",
    "            # --- Stage 1: Physics Layer (Windowing) ---\n",
    "            # Neck CT 最佳化: Center 50, Width 350 -> [-125, 225]\n",
    "            min_hu, max_hu = -125, 225\n",
    "            img = np.clip(img_np, min_hu, max_hu)\n",
    "\n",
    "            # --- Stage 2: Logic Layer (Normalization & CLAHE) ---\n",
    "            img = (img - min_hu) / (max_hu - min_hu) # 0.0 ~ 1.0\n",
    "            \n",
    "            # 轉 uint8 給 CLAHE\n",
    "            img_uint8 = (img * 255).astype(np.uint8)\n",
    "            \n",
    "            # CLAHE (ClipLimit=2.0, Grid=8x8)\n",
    "            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "            img_clahe = clahe.apply(img_uint8)\n",
    "            \n",
    "            # Base Image (Channel 0) - 這是 Pre-blur 的源頭\n",
    "            base_img = img_clahe.astype(np.float32) / 255.0\n",
    "            \n",
    "            features = [base_img] # [0]\n",
    "            \n",
    "            # --- Stage 3: Feature Layer (Extraction) ---\n",
    "            \n",
    "            # 3.1 Gaussian Blur (Context Channel)\n",
    "            # 修改參數: Kernel (7, 7), Sigma 1.1\n",
    "            blur_img = cv2.GaussianBlur(base_img, (7, 7), 1.1)\n",
    "            features.append(blur_img) # [1] Channel 1\n",
    "            \n",
    "            if self.use_grad:\n",
    "                ksize = 3 \n",
    "                \n",
    "                # --- Stream A: Post-Blur Gradients (Clean) ---\n",
    "                # 針對模糊後的圖算梯度，抓大輪廓\n",
    "                sobelx_clean = cv2.Sobel(blur_img, cv2.CV_32F, 1, 0, ksize=ksize)\n",
    "                sobely_clean = cv2.Sobel(blur_img, cv2.CV_32F, 0, 1, ksize=ksize)\n",
    "                lap_clean = cv2.Laplacian(blur_img, cv2.CV_32F, ksize=ksize)\n",
    "                \n",
    "                features.extend([\n",
    "                    self._normalize_minmax(np.abs(sobelx_clean)), # [2]\n",
    "                    self._normalize_minmax(np.abs(sobely_clean)), # [3]\n",
    "                    self._normalize_minmax(np.abs(lap_clean))     # [4]\n",
    "                ])\n",
    "                \n",
    "                # --- Stream B: Pre-Blur Gradients (Noisy/Detailed) ---\n",
    "                # 針對 CLAHE 原圖算梯度，抓細節 (包含雜訊)\n",
    "                # 這是你要求的「多給我」的部分\n",
    "                sobelx_raw = cv2.Sobel(base_img, cv2.CV_32F, 1, 0, ksize=ksize)\n",
    "                sobely_raw = cv2.Sobel(base_img, cv2.CV_32F, 0, 1, ksize=ksize)\n",
    "                lap_raw = cv2.Laplacian(base_img, cv2.CV_32F, ksize=ksize)\n",
    "                \n",
    "                features.extend([\n",
    "                    self._normalize_minmax(np.abs(sobelx_raw)),   # [5]\n",
    "                    self._normalize_minmax(np.abs(sobely_raw)),   # [6]\n",
    "                    self._normalize_minmax(np.abs(lap_raw))       # [7]\n",
    "                ])\n",
    "                \n",
    "            # --- Stage 4: Stacking ---\n",
    "            # 堆疊所有通道 -> (8, H, W)\n",
    "            final_img = np.stack(features, axis=0)\n",
    "            \n",
    "            return torch.from_numpy(final_img).float()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "para3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
