{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0da14ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_small_input_array(list_of_img_path, args):\n",
    "    \"\"\"\n",
    "    list_of_img_path: list of training image and corresponding target image path\n",
    "\t\te.g. [\"train_im_1_OR.png\",\"train_im_2_OR.png\",]\n",
    "\t\"\"\"\n",
    "    train_list, target_list, hist_list = list(), list(), list()\n",
    "    for img_path in list_of_img_path:\n",
    "        tmp_X, tmp_y, tmp_hist_list = load_one_data(img_path,\n",
    "                                                    img_path.replace(\"OR\", \"GT\"), args)\n",
    "        if args.add_feature != None:\n",
    "            feature = scipy.misc.imread(img_path.replace(\"OR\", args.add_feature),\n",
    "                flatten=False, mode='L').reshape(args.H,args.W,1).astype('float32')/255\n",
    "            tmp_X = np.dstack((tmp_X, feature))\n",
    "            tmp_X = np.array(tmp_X)\n",
    "        train_list.append(tmp_X);target_list.append(tmp_y)\n",
    "        if tmp_hist_list != None:\n",
    "            hist_list.append(tmp_hist_list)\n",
    "    return train_list, target_list, hist_list\n",
    "\n",
    "def crnn_gen_shuffle(x_set, batch_size, args, n):\n",
    "    if n == 2:\n",
    "        case_list = x_set.copy()\n",
    "        np.random.shuffle(case_list)\n",
    "        x_set = create_crnn_gen_file_list(case_list, args.training_path, args,n=n)\n",
    "        steps = int(np.floor(len(x_set) / float(batch_size)))\n",
    "        while True:\n",
    "            for i in range(steps):\n",
    "                batch_x = x_set[i * batch_size:(i + 1) * batch_size]\n",
    "                batch_X_0, batch_X_1, batch_Y, batch_Y_right = [], [], [], []\n",
    "                # print(batch_x)\n",
    "                for idx in range(len(batch_x)):\n",
    "                    tmp_x, tmp_y, tmp_hist_list = create_small_input_array(batch_x[idx], args)\n",
    "                    tmp_x = kw_preprocessing(np.array(tmp_x), args)\n",
    "                    if not args.reverse:\n",
    "                        batch_X_0.append(np.array(tmp_x[0]))\n",
    "                        batch_X_1.append(np.array(tmp_x[1]))\n",
    "                        batch_Y.append(np.array(tmp_y[1]))\n",
    "                    else:\n",
    "                        batch_X_0.append(np.array(tmp_x[1]))\n",
    "                        batch_X_1.append(np.array(tmp_x[0]))\n",
    "                        batch_Y.create_small_input_array(np.array(tmp_y[0]))\n",
    "                # if np.sum(batch_Y)==0:\n",
    "                #     yield [np.array(batch_X_0), np.array(batch_X_1)], np.array(batch_Y)\n",
    "                yield [np.array(batch_X_0), np.array(batch_X_1)], np.array(batch_Y)\n",
    "\n",
    "    elif n == 3:\n",
    "        case_list = x_set.copy()\n",
    "        np.random.shuffle(case_list)\n",
    "        x_set = create_crnn_gen_file_list(case_list, args.training_path, args,n=n)\n",
    "        steps = int(np.floor(len(x_set) / float(batch_size)))\n",
    "\n",
    "        def create_small_input3_array(list_of_img_path, args):\n",
    "            train_list, target_list = list(), list()\n",
    "            for img_path in list_of_img_path:\n",
    "                tmp_X, tmp_y, _ = load_one_data(img_path, img_path.replace(\"OR\", \"GT\"), args)\n",
    "                \n",
    "                if args.add_feature != None:\n",
    "                    feature = scipy.misc.imread(img_path.replace(\"OR\", args.add_feature),\n",
    "                        flatten=False, mode='L').reshape(args.H, args.W,1).astype('float32')/255\n",
    "                    tmp_X = np.dstack((tmp_X, feature))\n",
    "                    tmp_X = np.array(tmp_X)\n",
    "\n",
    "                train_list.append(tmp_X);target_list.append(tmp_y)           \n",
    "            return train_list, target_list\n",
    "\n",
    "        while True:\n",
    "            using_batch = []\n",
    "            for i in range(steps):\n",
    "                using_batch.append(x_set[i * batch_size:(i + 1) * batch_size])\n",
    "            np.random.shuffle(using_batch)\n",
    "\n",
    "            for batch_x in using_batch:\n",
    "\n",
    "                batch_X_0, batch_X_1, batch_X_2, batch_Y = [], [], [], []\n",
    "                for idx in range(len(batch_x)):\n",
    "                    tmp_x, tmp_y = create_small_input3_array(batch_x[idx], args)\n",
    "                    batch_X_0.append(np.array(tmp_x[0]))\n",
    "                    batch_X_1.append(np.array(tmp_x[1]))\n",
    "                    batch_X_2.append(np.array(tmp_x[2]))\n",
    "                    batch_Y.append(np.array(tmp_y[1]))\n",
    "                    \n",
    "                # if np.sum(batch_Y)==0:\n",
    "                #     yield [np.array(batch_X_0), np.array(batch_X_1), np.array(batch_X_2)], np.array(batch_Y)\n",
    "                #     yield [np.array(batch_X_0), np.array(batch_X_1), np.array(batch_X_2)], np.array(batch_Y)                                        \n",
    "                yield [np.array(batch_X_0), np.array(batch_X_1), np.array(batch_X_2)], np.array(batch_Y)\n",
    "            \n",
    "    else:\n",
    "        print(\"still support n = 2 or 3\")\n",
    "\n",
    "def create_crnn_gen_file_list(case_list, case_path_root, args,  n=2):\n",
    "    out_x = []\n",
    "    for case in case_list:\n",
    "        img_list = create_img_path_list(case_path_root + case)\n",
    "        out_x += [img_list[i:i + n] for i in range(0, len(img_list) - n + 1)]\n",
    "    return out_x\n",
    "\n",
    "def crnn_gen(x_set, batch_size, args, n):\n",
    "    steps = int(np.floor(len(x_set) / float(batch_size)))\n",
    "    if n == 2:\n",
    "        while True:\n",
    "            for i in range(steps):\n",
    "                batch_x = x_set[i * batch_size:(i + 1) * batch_size]\n",
    "                batch_X_0, batch_X_1, batch_Y = [], [], []\n",
    "                pair = []\n",
    "                for idx in range(len(batch_x)):\n",
    "                    tmp_x, tmp_y, tmp_hist_list = create_small_input_array(batch_x[idx], args)\n",
    "                    tmp_x = kw_preprocessing(np.array(tmp_x), args)\n",
    "                    # yield [np.array([tmp_x[0]]), np.array([tmp_x[1]])] , np.array([tmp_y[0]])#[np.array([tmp_y[0]]), np.array([tmp_y[1]])]\n",
    "                    batch_X_0.append(np.array(tmp_x[0]))\n",
    "                    batch_X_1.append(np.array(tmp_x[1]))\n",
    "                    # pair.append(np.array[tmp_x])\n",
    "                    batch_Y.append(np.array(tmp_y[1]))\n",
    "                yield [np.array(batch_X_0), np.array(batch_X_1)], np.array(batch_Y)\n",
    "    elif n == 3:\n",
    "        while True:\n",
    "            for i in range(steps):\n",
    "                batch_x = x_set[i * batch_size:(i + 1) * batch_size]\n",
    "                for idx in range(len(batch_x)):\n",
    "                    tmp_x, tmp_y, tmp_hist_list = create_small_input_array(batch_x[idx], args)\n",
    "                    tmp_x = kw_preprocessing(np.array(tmp_x), args)\n",
    "                    yield [np.array([tmp_x[0]]), np.array([tmp_x[1]]), np.array([tmp_x[2]])], np.array([tmp_y[1]])\n",
    "    else:\n",
    "        print(\"still support n = 2 or 3\")\n",
    "\n",
    "\n",
    "def large_dataset_gen(x_set, batch_size, args):\n",
    "    steps = int(np.floor(len(x_set) / float(batch_size)))\n",
    "    while True:\n",
    "        for i in range(steps):\n",
    "            batch_x = x_set[i * batch_size:(i + 1) * batch_size]\n",
    "            X, Y = [], []\n",
    "            for idx in range(len(batch_x)):\n",
    "                tmp_x, tmp_y, tmp_hist_list = create_small_input_array([batch_x[idx]], args)\n",
    "                tmp_x = kw_preprocessing(np.array(tmp_x), args)\n",
    "                X.append(tmp_x[0]);\n",
    "                Y.append(np.array(tmp_y[0]))\n",
    "            yield np.array(X), np.array(Y)\n",
    "        np.random.shuffle(x_set)\n",
    "\n",
    "\n",
    "def create_caselist(args):\n",
    "    df = pd.read_csv(args.index)\n",
    "    # case_list = os.listdir(args.training_path)\n",
    "    # num_case = len(case_list)\n",
    "    # split_num = [int(np.round(num_case*.6)),int(np.round(num_case*.8))] # train:valid:test = 6:2:2\n",
    "    train = df['train'].dropna().tolist()\n",
    "    valid = df['validation'].dropna().tolist()\n",
    "    test  = df['test'].dropna().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43bc620",
   "metadata": {},
   "source": [
    "### 從學長程式碼找到的對應loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e067bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weightedConsecutiveLoss(args):\n",
    "    def DL(y_true,y_pred):\n",
    "\t    return 1-((K.sum(y_true*y_pred,axis=[1,2])+K.epsilon())/(K.sum(y_true+y_pred,axis=[1,2])+K.epsilon()))-((K.sum((1-y_true)*(1-y_pred),axis=[1,2])+K.epsilon())/(K.sum((2-y_true-y_pred),axis=[1,2])+K.epsilon()))\n",
    "    def weightedConsecutiveDiceLoss(y_true, y_pred):\n",
    "        if args.loss_ratio != None and args.loss_ratio != 0:\n",
    "            if args.consecutive == 2:\n",
    "                currentRatio = ( args.loss_ratio / ( args.loss_ratio + 1 ) )\n",
    "                loss_1 = currentRatio * K.mean( DL( y_true, y_pred), 0 )\n",
    "                anotherRatio = ( 1 / (args.loss_ratio + 1 ) )\n",
    "                loss_2 = anotherRatio * K.mean( DL( y_true[:-1], y_pred[1:] ), 0 )\n",
    "                print(\"Using ratio [prev: curr]=[{:.2f},{:.2f}]\".format(anotherRatio, currentRatio) )\n",
    "                return K.mean(tf.concat([loss_1,loss_2], 0), 0)\n",
    "            else: # args.consecutive == 3\n",
    "                currentRatio = ( args.loss_ratio * 2 / ( args.loss_ratio * 2 + 2 ) )\n",
    "                lossCenter = currentRatio * K.mean( DL( y_true, y_pred), 0 )\n",
    "                anotherRatio = ( 1 / ( args.loss_ratio * 2 + 2 ) )\n",
    "                lossLeft  = anotherRatio * K.mean( DL( y_true[:-1], y_pred[1:] ), 0 )\n",
    "                lossRight = anotherRatio * K.mean( DL( y_true[1:], y_pred[:-1] ), 0 )\n",
    "                print(\"Using ratio [prev: curr: next]=[{:.2f},{:.2f},{:.2f}]\".format(anotherRatio,\n",
    "                                                            currentRatio, anotherRatio) )\n",
    "                res = K.mean(tf.concat([lossLeft, lossCenter, lossRight], 0), 0)\n",
    "                return res\n",
    "        elif args.loss_ratio == 0:\n",
    "            # dynamic weight\n",
    "            if args.consecutive == 3:\n",
    "                print(\"dynamic weight\")\n",
    "                Y = y_true\n",
    "                Y = K.concatenate([K.expand_dims(Y[0],0), Y, K.expand_dims(Y[-1],0)], axis=0)\n",
    "                prevCurrDiff = K.sum(K.abs(Y[1:]-Y[:-1]), axis=(1,2,3))\n",
    "                prevCurrDiffDivideSum = prevCurrDiff / K.sum(Y[:-1], axis=(1,2,3))*120\n",
    "                prevCurrDiffDivideSum = K.tf.where(K.tf.is_nan(prevCurrDiffDivideSum), K.zeros_like(prevCurrDiffDivideSum), prevCurrDiffDivideSum)\n",
    "                const = 2\n",
    "                mask = K.equal(prevCurrDiffDivideSum, K.zeros_like(prevCurrDiffDivideSum)) \n",
    "                mask = K.cast(mask, dtype='float32')\n",
    "                centerWeight = (const - 1) * mask + prevCurrDiffDivideSum\n",
    "                batchWeight = K.concatenate([K.expand_dims(centerWeight[1:]),\n",
    "                            K.expand_dims(K.tf.multiply(centerWeight[1:], centerWeight[:-1])),\n",
    "                            K.expand_dims(centerWeight[:-1])], axis=1)\n",
    "                denominator = K.sum(batchWeight, axis=1)\n",
    "\n",
    "\n",
    "                currentRatio = K.expand_dims(K.tf.multiply(centerWeight[1:], centerWeight[:-1])/ denominator)\n",
    "                currentRatio = K.tf.where(K.tf.is_nan(currentRatio), K.ones_like(currentRatio)/3, currentRatio)\n",
    "                prevRatio = K.expand_dims(centerWeight[1:] / denominator)\n",
    "                prevRatio = K.tf.where(K.tf.is_nan(prevRatio), K.ones_like(prevRatio)/3, prevRatio)\n",
    "                nextRatio = K.expand_dims(centerWeight[:-1] / denominator)\n",
    "                nextRatio = K.tf.where(K.tf.is_nan(nextRatio), K.ones_like(nextRatio)/3, nextRatio)\n",
    "\n",
    "                lossCenter = K.mean(currentRatio * DL( Y[1:-1], y_pred), 0 )\n",
    "                lossLeft  = K.mean(prevRatio * DL( Y[:-2], y_pred ), 0 )\n",
    "                lossRight = K.mean(nextRatio * DL( Y[2:], y_pred ), 0 )\n",
    "\n",
    "\n",
    "                res = K.mean(tf.concat([lossLeft, lossCenter, lossRight], 0), 0)\n",
    "                return res#K.mean(tf.concat([lossLeft, lossCenter, lossRight], 0), 0)\n",
    "            else:\n",
    "                print(\"not for 2\")\n",
    "                # sys.exit()\n",
    "    weightedConsecutiveDiceLoss.__name__ = \"weightedConsecutiveDiceLoss\"\n",
    "    return weightedConsecutiveDiceLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ba8966",
   "metadata": {},
   "source": [
    "### 新的model (待verify)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6e23e3",
   "metadata": {},
   "source": [
    "#### dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9b1eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from pathlib import Path\n",
    "\n",
    "class CRNNDataset(Dataset):\n",
    "    def __init__(self, root_dir, target_dir=None, n_frames=3, is_train=True, \n",
    "                 use_blur=False, use_grad=False, use_hist=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir: 訓練圖片的根目錄 (裡面包含各個 Case 的資料夾，或直接是圖片)\n",
    "            target_dir: Ground Truth 的根目錄\n",
    "            n_frames: 2 或 3 (對應學長的 consecutive)\n",
    "            use_blur: 是否使用高斯模糊特徵 (學長的 args.blur)\n",
    "            use_grad: 是否使用梯度特徵 (學長的 args.gradient_preprocess)\n",
    "            use_hist: 是否使用直方圖特徵 (學長的 input_hist)\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.target_dir = target_dir\n",
    "        self.n_frames = n_frames\n",
    "        self.is_train = is_train\n",
    "        \n",
    "        # 特徵工程開關\n",
    "        self.use_blur = use_blur\n",
    "        self.use_grad = use_grad\n",
    "        self.use_hist = use_hist\n",
    "\n",
    "        # 1. 建立滑動視窗索引 (Sliding Window Indexing)\n",
    "        # 格式: [ (prev_path, curr_path, next_path), label_path ]\n",
    "        self.samples = self._make_dataset()\n",
    "\n",
    "    def _make_dataset(self):\n",
    "        \"\"\"\n",
    "        模擬學長的 create_crnn_gen_file_list\n",
    "        \"\"\"\n",
    "        samples = []\n",
    "        \n",
    "        # 假設 root_dir 裡面是各個 Case 的資料夾 (例如: case1, case2...)\n",
    "        # 如果你的結構是直接一堆 png，請把 root_dir 當作單一 case 處理\n",
    "        if not os.path.exists(self.root_dir):\n",
    "            raise ValueError(f\"Directory not found: {self.root_dir}\")\n",
    "\n",
    "        # 這裡假設 root_dir 下面有很多子資料夾，每個資料夾代表一個 Volume\n",
    "        # 如果你的資料結構是扁平的 (直接在 root_dir 下就是 1.png, 2.png...)\n",
    "        # 那就把 case_dirs 設為 [self.root_dir]\n",
    "        case_dirs = [os.path.join(self.root_dir, d) for d in os.listdir(self.root_dir) \n",
    "                     if os.path.isdir(os.path.join(self.root_dir, d))]\n",
    "        \"\"\"\n",
    "        以上的寫法等價於\n",
    "        case_dirs = []\n",
    "        for d in os.listdir(self.root_dir):\n",
    "        full_path = os.path.join(self.root_dir, d)\n",
    "        if os.path.isdir(full_path):\n",
    "        case_dirs.append(full_path)\n",
    "        \"\"\"\n",
    "        # 如果找不到子資料夾，就假設 root_dir 本身就是一個 case\n",
    "        ## 視為單一case \n",
    "        if not case_dirs:\n",
    "            case_dirs = [self.root_dir]\n",
    "\n",
    "        for case_path in case_dirs:\n",
    "            # 讀取該 Case 下所有 png 並排序 (學長的 create_img_path_list 邏輯)\n",
    "            # 排序很重要！必須是 1.png, 2.png, 3.png...\n",
    "            imgs = sorted([f for f in os.listdir(case_path) if f.endswith('.png')],\n",
    "                          key=lambda x: int(os.path.splitext(x)[0]))\n",
    "            \n",
    "            full_img_paths = [os.path.join(case_path, f) for f in imgs]\n",
    "            ## 此時full_img_paths為儲存此迴圈中的所有path之排序\n",
    "            \n",
    "            if self.target_dir:\n",
    "                # 假設 Target 的結構跟 Input 一模一樣\n",
    "                case_name = os.path.basename(case_path)\n",
    "                ## case_path是在root_dir後 png檔案外面那層資料夾\n",
    "                target_case_path = os.path.join(self.target_dir, case_name)\n",
    "                # 如果 target 結構是扁平的，要自己調整這裡\n",
    "                if not os.path.exists(target_case_path): \n",
    "                     target_case_path = self.target_dir # Fallback\n",
    "                \n",
    "                full_target_paths = [os.path.join(target_case_path, f) for f in imgs]\n",
    "            \n",
    "            # 製作滑動視窗\n",
    "            # 如果 n=3, 會有 [i, i+1, i+2]\n",
    "            for i in range(len(full_img_paths) - self.n_frames + 1):\n",
    "                window_imgs = full_img_paths[i : i + self.n_frames]\n",
    "                \n",
    "                # Label 對應的是中間那張 (curr) 或是最後一張?\n",
    "                # 學長邏輯: return batch_Y.append(tmp_y[1]) -> n=3 時取中間\n",
    "                # n=2 時取後面那個? 學長代碼: yield ... np.array(batch_Y) (batch_Y append tmp_y[1])\n",
    "                # 結論：Label 總是取 window 中的 index=1 (第二張)\n",
    "                \n",
    "                label_path = None\n",
    "                if self.target_dir:\n",
    "                    # 取 window 中間 (index 1) 的 label\n",
    "                    # 如果 n=2, index 1 就是第二張 (Curr)\n",
    "                    label_idx = i + 1 \n",
    "                    label_path = full_target_paths[label_idx]\n",
    "                \n",
    "                samples.append((window_imgs, label_path))\n",
    "                \n",
    "        return samples ## return的samples 會是一個系列的切片位置 對應這組系列切片應該產出的GT位置\n",
    "\n",
    "    def _load_image(self, path): ## 讀image並且做標準化\n",
    "        # 替換 scipy.misc.imread -> cv2.imread\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            raise ValueError(f\"Failed to load image: {path}\")\n",
    "        img = img.astype(np.float32)\n",
    "        \n",
    "        # Normalization (0~1)\n",
    "        # 學長邏輯: (img - min) / (max - min)\n",
    "        img_min, img_max = img.min(), img.max()\n",
    "        if img_max > img_min:\n",
    "            img = (img - img_min) / (img_max - img_min)\n",
    "        else:\n",
    "            img = img * 0 # 避免除以 0\n",
    "            \n",
    "        return img\n",
    "\n",
    "    def _preprocess(self, img_np):\n",
    "        \"\"\"\n",
    "        重現學長的 kw_preprocessing (Blur, Gradient)\n",
    "        img_np shape: (H, W)\n",
    "        Return shape: (C, H, W) -> C 可能是 1, 3, 5... 取決於特徵\n",
    "        \"\"\"\n",
    "        processed_channels = [img_np] # 原始圖\n",
    "        \n",
    "        # 1. Blur (高斯模糊)\n",
    "        if self.use_blur:\n",
    "            # 學長用的是 sigma=[2], kernel=7\n",
    "            blur = cv2.GaussianBlur(img_np, (7, 7), 2)\n",
    "            # Normalize blur\n",
    "            b_min, b_max = blur.min(), blur.max()\n",
    "            if b_max > b_min:\n",
    "                blur = (blur - b_min) / (b_max - b_min)\n",
    "            processed_channels.append(blur)\n",
    "            \n",
    "        # Stack 起來變成 (H, W, C_temp) 為了做 Gradient\n",
    "        feature_stack = np.stack(processed_channels, axis=-1) \n",
    "        \n",
    "        # 2. Gradient (Sobel + Laplacian)\n",
    "        if self.use_grad:\n",
    "            grad_channels = []\n",
    "            ksize = 5\n",
    "            # 對每個現有的 channel (Original, Blur) 做 gradient\n",
    "            for i in range(feature_stack.shape[-1]):\n",
    "                src = feature_stack[:, :, i]\n",
    "                \n",
    "                # Laplacian\n",
    "                lap = cv2.Laplacian(src, cv2.CV_32F, ksize=ksize)\n",
    "                # Normalize Lap\n",
    "                l_min, l_max = lap.min(), lap.max()\n",
    "                if l_max > l_min: lap = (lap - l_min) / (l_max - l_min)\n",
    "                \n",
    "                # Sobel\n",
    "                sobelx = cv2.Sobel(src, cv2.CV_32F, 1, 0, ksize=ksize)\n",
    "                sobely = cv2.Sobel(src, cv2.CV_32F, 0, 1, ksize=ksize)\n",
    "                sobel = np.maximum(np.abs(sobelx), np.abs(sobely))\n",
    "                # Normalize Sobel\n",
    "                s_min, s_max = sobel.min(), sobel.max()\n",
    "                if s_max > s_min: sobel = (sobel - s_min) / (s_max - s_min)\n",
    "                \n",
    "                grad_channels.append(sobel)\n",
    "                grad_channels.append(lap)\n",
    "            \n",
    "            # 將 Gradient 特徵加回去\n",
    "            # 學長邏輯：[Original, Blur, Sobel_Org, Lap_Org, Sobel_Blur, Lap_Blur]\n",
    "            # 這裡我們簡化處理，全部疊加\n",
    "            processed_channels.extend(grad_channels)\n",
    "\n",
    "        # Final Stack: (H, W, C) -> Transpose to (C, H, W) for PyTorch\n",
    "        final_img = np.stack(processed_channels, axis=0) \n",
    "        return torch.from_numpy(final_img).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        window_paths, label_path = self.samples[idx]\n",
    "        \n",
    "        # 讀取並處理 Input (Prev, Curr, Next)\n",
    "        tensors = []\n",
    "        for p in window_paths:\n",
    "            img = self._load_image(p)    # Load & Norm\n",
    "            tensor = self._preprocess(img) # Blur & Grad & ToTensor\n",
    "            tensors.append(tensor) ## tensor w/ the shape of (C,H,W)\n",
    "            \n",
    "        # 根據 n_frames 組裝 dict\n",
    "        sample = {}\n",
    "        if self.n_frames == 3:\n",
    "            sample = {\n",
    "                'prev': tensors[0],\n",
    "                'curr': tensors[1],\n",
    "                'next': tensors[2]\n",
    "            }\n",
    "        elif self.n_frames == 2:\n",
    "            sample = {\n",
    "                'prev': tensors[0],\n",
    "                'curr': tensors[1]\n",
    "            }\n",
    "\n",
    "        # 讀取 Label\n",
    "        if self.target_dir and label_path:\n",
    "            # Label 不需要做 Blur/Grad，只需要讀取跟 Normalize (通常是 0/1)\n",
    "            lbl = cv2.imread(label_path, cv2.IMREAD_GRAYSCALE)\n",
    "            lbl = (lbl / 255.0).astype(np.float32) # 轉成 0~1\n",
    "            lbl = torch.from_numpy(lbl).unsqueeze(0) # (1, H, W)\n",
    "            sample['label'] = lbl\n",
    "            \n",
    "        return sample\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1602aac4",
   "metadata": {},
   "source": [
    "#### loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dd6cd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DoubleDiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1e-6):\n",
    "        super(DoubleDiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        PyTorch Shape: [Batch, Channel, H, W]\n",
    "        TF Original: axis=[1,2] -> H, W (Channel is last in TF)\n",
    "        PyTorch Equivalent: Sum over [2, 3] if input is [B, C, H, W]\n",
    "        \"\"\"\n",
    "        # 確保輸入在 0~1 之間 (如果模型最後沒有 Sigmoid，這裡要加)\n",
    "        # y_pred = torch.sigmoid(y_pred) \n",
    "        \n",
    "        # 展平 H, W 維度以便計算\n",
    "        # [B, C, H, W] -> [B, C, H*W]\n",
    "        batch, channel, h, w = y_true.shape\n",
    "        y_true_f = y_true.view(batch, channel, -1)\n",
    "        y_pred_f = y_pred.view(batch, channel, -1)\n",
    "\n",
    "        # Term 1: Foreground Dice\n",
    "        intersection = torch.sum(y_true_f * y_pred_f, dim=2)\n",
    "        union = torch.sum(y_true_f + y_pred_f, dim=2)\n",
    "        term1 = (intersection + self.smooth) / (union + self.smooth)\n",
    "\n",
    "        # Term 2: Background Dice (1 - y)\n",
    "        intersection_inv = torch.sum((1 - y_true_f) * (1 - y_pred_f), dim=2)\n",
    "        union_inv = torch.sum((2 - y_true_f - y_pred_f), dim=2)\n",
    "        term2 = (intersection_inv + self.smooth) / (union_inv + self.smooth)\n",
    "\n",
    "        # Final Loss: 1 - Term1 - Term2\n",
    "        # 注意：通常 Dice Loss 是 1 - Dice。這裡是 1 - FG_Dice - BG_Dice\n",
    "        # 但這可能導致負值 (因為 Dice 最大是 1)，學長原公式是這樣寫的，我們先照搬。\n",
    "        # 原公式：1 - (FG) - (BG)。如果 FG=1, BG=1，Loss = -1。\n",
    "        # 建議檢查一下是否應該是 1 - (FG + BG)/2 或者是 2 - FG - BG\n",
    "        # 為了忠實復刻，這裡保持原樣：\n",
    "        return 1 - term1 - term2\n",
    "\n",
    "class WeightedConsecutiveLoss(nn.Module):\n",
    "    def __init__(self, loss_ratio=0.5, consecutive=3, dynamic_weight=False):\n",
    "        super(WeightedConsecutiveLoss, self).__init__()\n",
    "        self.loss_ratio = loss_ratio\n",
    "        self.consecutive = consecutive\n",
    "        self.dynamic_weight = dynamic_weight\n",
    "        self.base_loss = DoubleDiceLoss()\n",
    "\n",
    "    def forward(self, y_true, y_pred):\n",
    "        # 假設 y_true, y_pred 形狀為 [Batch, C, H, W]\n",
    "        \n",
    "        # 1. 固定權重模式 (Fixed Ratio)\n",
    "        if not self.dynamic_weight and self.loss_ratio != 0:\n",
    "            if self.consecutive == 2:\n",
    "                # 權重計算\n",
    "                current_ratio = self.loss_ratio / (self.loss_ratio + 1)\n",
    "                neighbor_ratio = 1 / (self.loss_ratio + 1)\n",
    "                \n",
    "                print(f\"Ratio: Curr={current_ratio:.2f}, Prev={neighbor_ratio:.2f}\")\n",
    "\n",
    "                loss_center = current_ratio * self.base_loss(y_true, y_pred)\n",
    "                \n",
    "                # Cross-Temporal Loss: True[t] vs Pred[t+1]\n",
    "                # 注意：這裡會讓 Batch Size 變少 1\n",
    "                loss_prev = neighbor_ratio * self.base_loss(y_true[:-1], y_pred[1:])\n",
    "                \n",
    "                # 為了將 loss 合併，我們取 mean\n",
    "                return torch.mean(loss_center) + torch.mean(loss_prev)\n",
    "\n",
    "            else: # consecutive == 3 (CRNN Default)\n",
    "                # 權重計算\n",
    "                total_share = self.loss_ratio * 2 + 2\n",
    "                current_ratio = (self.loss_ratio * 2) / total_share\n",
    "                neighbor_ratio = 1 / total_share\n",
    "\n",
    "                # loss_center: [Batch]\n",
    "                loss_center = current_ratio * self.base_loss(y_true, y_pred)\n",
    "                \n",
    "                # loss_left: True[t] vs Pred[t+1] (Shifted Left)\n",
    "                loss_left = neighbor_ratio * self.base_loss(y_true[:-1], y_pred[1:])\n",
    "                \n",
    "                # loss_right: True[t] vs Pred[t-1] (Shifted Right)\n",
    "                loss_right = neighbor_ratio * self.base_loss(y_true[1:], y_pred[:-1])\n",
    "\n",
    "                # 原代碼使用了 tf.concat 然後 mean。\n",
    "                # 在 PyTorch 直接加總 mean 即可，數學上等價\n",
    "                final_loss = torch.mean(loss_center) + torch.mean(loss_left) + torch.mean(loss_right)\n",
    "                return final_loss\n",
    "\n",
    "        # 2. 動態權重模式 (Dynamic Weight) - 只有 consecutive=3\n",
    "        elif self.dynamic_weight or self.loss_ratio == 0:\n",
    "            if self.consecutive != 3:\n",
    "                raise ValueError(\"Dynamic weight only supports consecutive=3\")\n",
    "            \n",
    "            # --- 計算動態權重 (Dynamic Logic) ---\n",
    "            # TF: Y = K.concatenate([Y[0], Y, Y[-1]]) padding batch\n",
    "            # 這是為了計算每一幀跟前後幀的差異\n",
    "            y_pad = torch.cat([y_true[0:1], y_true, y_true[-1:]], dim=0)\n",
    "            \n",
    "            # 差異計算: |Y[t+1] - Y[t]|\n",
    "            # Sum over (C, H, W) -> dims [1, 2, 3]\n",
    "            diff = torch.abs(y_pad[1:] - y_pad[:-1])\n",
    "            prev_curr_diff = torch.sum(diff, dim=[1, 2, 3]) # [Batch+1]\n",
    "            \n",
    "            # 歸一化差異\n",
    "            y_sum = torch.sum(y_true, dim=[1, 2, 3]) # [Batch]\n",
    "            # y_pad[:-1] 對應的是原長度的 padding 版本，這裡簡化邏輯：\n",
    "            # 學長原代碼：prevCurrDiff / sum(Y[:-1]) * 120\n",
    "            # 為了對齊長度，我們取 diff 的前 N 個\n",
    "            diff_metric = (prev_curr_diff[:-1] / (y_sum + 1e-6)) * 120\n",
    "            \n",
    "            # 處理 NaN\n",
    "            diff_metric = torch.nan_to_num(diff_metric, 0.0)\n",
    "            \n",
    "            const = 2.0\n",
    "            # mask: if diff_metric == 0\n",
    "            mask = (diff_metric == 0).float()\n",
    "            center_weight_raw = (const - 1) * mask + diff_metric\n",
    "            \n",
    "            # 建構三項權重\n",
    "            # Batch Weight: [Left, Center, Right]\n",
    "            # Center = diff[t] * diff[t-1]\n",
    "            cw_curr = center_weight_raw[1:]\n",
    "            cw_prev = center_weight_raw[:-1]\n",
    "            \n",
    "            w_center = cw_curr * cw_prev\n",
    "            w_left = cw_curr\n",
    "            w_right = cw_prev\n",
    "            \n",
    "            denominator = w_center + w_left + w_right + 1e-6\n",
    "            \n",
    "            # 最終 Ratio [Batch-1] (因為 diff 會少一個維度)\n",
    "            # 注意：這裡維度對齊非常痛苦，建議如果是初期復刻，\n",
    "            # 強烈建議先用 Fixed Ratio (loss_ratio != 0)。\n",
    "            # Dynamic Weight 很容易因為 Batch Size 太小而算出一堆 NaN。\n",
    "            \n",
    "            ratio_center = w_center / denominator\n",
    "            ratio_left = w_left / denominator\n",
    "            ratio_right = w_right / denominator\n",
    "            \n",
    "            # 計算 Loss\n",
    "            # 因為使用了 padding 和 shifting，這裡的 batch size 會縮減\n",
    "            # 我們需要對齊 loss 和 ratio 的長度\n",
    "            \n",
    "            # 取中間段的 loss\n",
    "            l_c = self.base_loss(y_true[1:-1], y_pred[1:-1])\n",
    "            l_l = self.base_loss(y_true[:-2], y_pred[1:-1]) # y_true[t-1] vs y_pred[t]\n",
    "            l_r = self.base_loss(y_true[2:], y_pred[1:-1])  # y_true[t+1] vs y_pred[t]\n",
    "            \n",
    "            # 確保 ratio 長度跟 loss 一樣 (Batch - 2)\n",
    "            # 這裡做一個簡單的 slice\n",
    "            valid_len = l_c.shape[0]\n",
    "            r_c = ratio_center[:valid_len].view(-1, 1) # view 用於廣播\n",
    "            r_l = ratio_left[:valid_len].view(-1, 1)\n",
    "            r_r = ratio_right[:valid_len].view(-1, 1)\n",
    "\n",
    "            final_loss = torch.mean(r_c * l_c + r_l * l_l + r_r * l_r)\n",
    "            return final_loss\n",
    "\n",
    "        else:\n",
    "            return self.base_loss(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcb3af2",
   "metadata": {},
   "source": [
    "#### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0c55805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized. Running forward pass...\n",
      "Output shape: torch.Size([1, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\"\"\"\n",
    "# 1. 配置管理 (取代 argparse)\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    block_channels: list = (64, 128, 256, 512) # 範例深度\n",
    "    block_conv: int = 2        # 每個 Block 有幾層 Conv\n",
    "    dropout_rate: float = 0.25\n",
    "    n_frames: int = 3          # n=2 或 n=3 (對應 prev, curr, next)\n",
    "    input_channels: int = 1    # 灰階為 1，RGB 為 3\n",
    "    num_classes: int = 2       # 最終輸出的類別數 (對應 output_layer)\n",
    "\"\"\"\n",
    "\n",
    "# 2. 基礎卷積塊 (取代 set_or_get_conv2d)\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, num_layers, dropout_rate):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            # 第一層負責改變通道數，後續層維持通道數\n",
    "            cin = in_ch if i == 0 else out_ch\n",
    "            self.layers.append(nn.Sequential(\n",
    "                nn.Conv2d(cin, out_ch, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(out_ch),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ))\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        skip = x  # 保存用於 Skip Connection 的特徵 (Before Pooling)\n",
    "        out = self.pool(x)\n",
    "        out = self.dropout(out)\n",
    "        return out, skip\n",
    "\n",
    "# 3. 上採樣塊 (取代 Decoder 中的重複邏輯)\n",
    "class UpBlock(nn.Module):\n",
    "    def __init__(self, in_ch, skip_ch, out_ch, dropout_rate):\n",
    "        super().__init__()\n",
    "        # 對應 Conv2DTranspose(strides=2)\n",
    "        self.up = nn.ConvTranspose2d(in_ch, out_ch, kernel_size=2, stride=2)\n",
    "        self.bn_up = nn.BatchNorm2d(out_ch)\n",
    "        \n",
    "        # 融合後的卷積 (Skip connection channel size + Upsampled channel size)\n",
    "        # 根據舊代碼：concatenate([curr_skip, prev_skip, up]) -> 2 * skip_ch + out_ch\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(out_ch + 2 * skip_ch, out_ch, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, skip_curr, skip_prev):\n",
    "        x = self.up(x)\n",
    "        x = self.bn_up(x)\n",
    "        \n",
    "        # 確保維度匹配 (處理 padding 問題)\n",
    "        if x.size() != skip_curr.size():\n",
    "            x = F.interpolate(x, size=skip_curr.shape[2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "        # Concatenate: [Curr, Prev, Up]\n",
    "        cat_x = torch.cat([skip_curr, skip_prev, x], dim=1)\n",
    "        return self.conv(cat_x)\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    # 1. 輸入與輸出規格\n",
    "    input_channels: int = 1      # 輸入圖片的通道數 (醫學影像通常是 1，若是 RGB 則是 3)\n",
    "    num_classes: int = 1         # 最終輸出的類別數 (若是做二元分割如：肝臟/背景，則為 1)\n",
    "    \n",
    "    # 2. 模型深度與寬度\n",
    "    # 這決定了 U-Net 有幾層，以及每層變多厚\n",
    "    # [64, 128, 256, 512] 代表有 4 個 Encoder Block，最底層是 512\n",
    "    block_channels: List[int] = field(default_factory=lambda: [64, 128, 256, 512])\n",
    "    \n",
    "    # 3. 區塊內部的複雜度\n",
    "    block_conv: int = 2          # 每個 ConvBlock 裡面重複做幾次卷積 (num_layers)\n",
    "    \n",
    "    # 4. 時序相關 (Concurrent 的核心)\n",
    "    n_frames: int = 3            # 一次輸入幾張圖？(2 or 3) 這會影響 Bottleneck 的輸入厚度\n",
    "    \n",
    "    # 5. 正則化參數\n",
    "    dropout_rate: float = 0.5    # Dropout 的比例\n",
    "\n",
    "# 4. 主模型：Concurrent CRNN (Siamese U-Net)\n",
    "class ConcurrentUNet(nn.Module):\n",
    "    def __init__(self, config: ModelConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        # --- Encoder (權重共享) ---\n",
    "        self.encoder_blocks = nn.ModuleList()\n",
    "        in_ch = config.input_channels\n",
    "        \n",
    "        for out_ch in config.block_channels:\n",
    "            self.encoder_blocks.append(\n",
    "                ConvBlock(in_ch, out_ch, config.block_conv, config.dropout_rate)\n",
    "            )\n",
    "            in_ch = out_ch # 更新下一層的輸入\n",
    "            \n",
    "        # --- Bottleneck (最底層) ---\n",
    "        # 根據舊代碼：如果是 n=3，concatenate(prev, curr, next)\n",
    "        # 輸入通道數 = 最後一層 Encoder Channel * n_frames\n",
    "        bottleneck_in_ch = config.block_channels[-1] * config.n_frames \n",
    "        bottleneck_out_ch = config.block_channels[-1]\n",
    "        \n",
    "        self.bottleneck_conv = nn.Sequential(\n",
    "            nn.Conv2d(bottleneck_in_ch, bottleneck_out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(bottleneck_out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(config.dropout_rate)\n",
    "        )\n",
    "\n",
    "        # --- Decoder ---\n",
    "        self.decoder_blocks = nn.ModuleList()\n",
    "        # 倒序遍歷 channels (排除最後一層，因為那是 bottleneck 的輸入)\n",
    "        rev_channels = config.block_channels[::-1] \n",
    "        \n",
    "        for i in range(len(rev_channels) - 1):\n",
    "            in_ch = rev_channels[i]\n",
    "            skip_ch = rev_channels[i+1] # 下一層的 channel (因為是倒序)\n",
    "            out_ch = rev_channels[i+1]\n",
    "            \n",
    "            self.decoder_blocks.append(\n",
    "                UpBlock(in_ch, skip_ch, out_ch, config.dropout_rate)\n",
    "            )\n",
    "            \n",
    "        # 最終輸出層\n",
    "        self.final_conv = nn.Conv2d(config.block_channels[0], config.num_classes, kernel_size=1)\n",
    "\n",
    "    def forward_single_branch(self, x):\n",
    "        \"\"\"跑單一分支的 Encoder\"\"\"\n",
    "        skips = []\n",
    "        for block in self.encoder_blocks:\n",
    "            x, skip = block(x)\n",
    "            skips.append(skip)\n",
    "        return x, skips\n",
    "\n",
    "    def forward(self, x_prev, x_curr, x_next=None):\n",
    "        # 1. Encoder 階段 (權重共享：同一個 self.encoder_blocks 跑多次)\n",
    "        feat_prev, skips_prev = self.forward_single_branch(x_prev)\n",
    "        feat_curr, skips_curr = self.forward_single_branch(x_curr)\n",
    "        \n",
    "        feats = [feat_prev, feat_curr]\n",
    "        if self.config.n_frames == 3 and x_next is not None:\n",
    "            feat_next, _ = self.forward_single_branch(x_next)\n",
    "            feats.append(feat_next) # [Prev, Curr, Next]\n",
    "        \n",
    "        # 2. Bottleneck 融合\n",
    "        # 舊代碼邏輯：concatenate([prev_last, curr_last, (next_last)])\n",
    "        bottleneck = torch.cat(feats, dim=1) \n",
    "        x = self.bottleneck_conv(bottleneck)\n",
    "        \n",
    "        # 3. Decoder 階段\n",
    "        # 需要倒序取出 skips (因為 Decoder 是從底層往上)\n",
    "        # skips 列表是 [Block0, Block1, Block2, Block3(Bottleneck input)]\n",
    "        # 我們需要從 Block2 開始往回拿\n",
    "        \n",
    "        for i, up_block in enumerate(self.decoder_blocks):\n",
    "            # 取得對應層級的 skip connection\n",
    "            # i=0 時，處理的是倒數第二層的特徵\n",
    "            idx = -(i + 2) \n",
    "            s_curr = skips_curr[idx]\n",
    "            s_prev = skips_prev[idx]\n",
    "            \n",
    "            x = up_block(x, s_curr, s_prev)\n",
    "            \n",
    "        # 4. 輸出\n",
    "        logits = self.final_conv(x)\n",
    "        return logits\n",
    "\n",
    "# --- 測試區 ---\n",
    "if __name__ == '__main__':\n",
    "    # 模擬輸入 (Batch=1, Channel=1, H=256, W=256)\n",
    "    dummy_prev = torch.randn(1, 1, 256, 256)\n",
    "    dummy_curr = torch.randn(1, 1, 256, 256)\n",
    "    dummy_next = torch.randn(1, 1, 256, 256)\n",
    "\n",
    "    # 初始化配置與模型\n",
    "    cfg = ModelConfig(n_frames=3, block_channels=[32, 64, 128])\n",
    "    model = ConcurrentUNet(cfg)\n",
    "    \n",
    "    # 執行 Forward Pass\n",
    "    print(\"Model initialized. Running forward pass...\")\n",
    "    output = model(dummy_prev, dummy_curr, dummy_next)\n",
    "    print(\"Output shape:\", output.shape) # 預期: [1, 2, 256, 256]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8943e23",
   "metadata": {},
   "source": [
    "#### matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d373b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def calculate_metrics(pred_logits, target, threshold=0.5):\n",
    "    \"\"\"\n",
    "    一次計算所有指標：Dice, IoU (OM), Accuracy\n",
    "    pred_logits: (B, 1, H, W) 未經過 Sigmoid 的輸出\n",
    "    target: (B, 1, H, W) 0 或 1\n",
    "    \"\"\"\n",
    "    # 1. 前處理\n",
    "    pred_probs = torch.sigmoid(pred_logits)\n",
    "    pred_bin = (pred_probs > threshold).float()\n",
    "    \n",
    "    # 為了計算方便，展平\n",
    "    pred_flat = pred_bin.view(-1)\n",
    "    target_flat = target.view(-1)\n",
    "    \n",
    "    # 2. 核心數值\n",
    "    intersection = (pred_flat * target_flat).sum()\n",
    "    pred_sum = pred_flat.sum()\n",
    "    target_sum = target_flat.sum()\n",
    "    \n",
    "    # epsilon 防止除以 0\n",
    "    eps = 1e-6\n",
    "    \n",
    "    # 3. 計算指標\n",
    "    # Dice Score\n",
    "    dice = (2. * intersection + eps) / (pred_sum + target_sum + eps)\n",
    "    \n",
    "    # IoU (Overlap Metric - OM)\n",
    "    # Union = A + B - Inter\n",
    "    union = pred_sum + target_sum - intersection\n",
    "    iou = (intersection + eps) / (union + eps)\n",
    "    \n",
    "    # Accuracy (Pixel-wise)\n",
    "    # 正確預測的像素數 / 總像素數\n",
    "    correct = (pred_flat == target_flat).float().sum()\n",
    "    total = torch.tensor(target_flat.numel()).float().to(pred_flat.device)\n",
    "    acc = correct / total\n",
    "    \n",
    "    return {\n",
    "        \"dice\": dice.item(),\n",
    "        \"om\": iou.item(),  # 學長的 OM 就是 IoU\n",
    "        \"acc\": acc.item()\n",
    "    }\n",
    "\n",
    "class VolumeMetrics:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.intersection = 0\n",
    "        self.union = 0\n",
    "        self.pred_sum = 0\n",
    "        self.gt_sum = 0\n",
    "        self.fp_count = 0\n",
    "        self.tn_count = 0\n",
    "\n",
    "    def update(self, pred, gt):\n",
    "        \"\"\"\n",
    "        輸入單張或多張 Slice 的預測結果與 GT\n",
    "        pred: (B, H, W) 0 or 1 (Binary)\n",
    "        gt:   (B, H, W) 0 or 1 (Binary)\n",
    "        \"\"\"\n",
    "        # 轉成 numpy 並確保是 boolean/int\n",
    "        if hasattr(pred, 'cpu'): pred = pred.cpu().numpy()\n",
    "        if hasattr(gt, 'cpu'): gt = gt.cpu().numpy()\n",
    "        \n",
    "        pred = pred.astype(np.uint8)\n",
    "        gt = gt.astype(np.uint8)\n",
    "\n",
    "        # 核心計算 (與學長邏輯一致)\n",
    "        self.intersection += np.sum(pred * gt)\n",
    "        self.pred_sum += np.sum(pred)\n",
    "        self.gt_sum += np.sum(gt)\n",
    "        \n",
    "        # 用於計算 FP (學長定義: FP = (Pred總和 / GT總和) - Sensitivity)\n",
    "        # 或者傳統定義: FP pixels = pred & (1-gt)\n",
    "        self.fp_count += np.sum(pred * (1 - gt)) \n",
    "        \n",
    "    def get_metrics(self):\n",
    "        \"\"\"回傳計算好的字典\"\"\"\n",
    "        # 避免除以 0\n",
    "        epsilon = 1e-6\n",
    "        \n",
    "        # 1. Overlap Metric (OM) / IoU\n",
    "        # 學長公式: inter / (pred + gt - inter)\n",
    "        om = self.intersection / (self.pred_sum + self.gt_sum - self.intersection + epsilon)\n",
    "        \n",
    "        # 2. True Positive Rate (TP) / Sensitivity\n",
    "        # 學長公式: inter / gt\n",
    "        tp = self.intersection / (self.gt_sum + epsilon)\n",
    "        \n",
    "        # 3. False Positive Rate (FP) - Ansen's definition\n",
    "        # 學長公式: (pred_sum / gt_sum) - sensitivity\n",
    "        # 數學上等價於: (pred_sum - intersection) / gt_sum = fp_pixels / gt_sum\n",
    "        fp = self.fp_count / (self.gt_sum + epsilon)\n",
    "        \n",
    "        # 4. Dice Score (DR)\n",
    "        # 學長公式: 2 * inter / (pred + gt)\n",
    "        dr = 2 * self.intersection / (self.pred_sum + self.gt_sum + epsilon)\n",
    "\n",
    "        return {\n",
    "            \"OM\": om,\n",
    "            \"TP\": tp,\n",
    "            \"FP\": fp,\n",
    "            \"Dice\": dr,\n",
    "            \"GT_Vol\": self.gt_sum,\n",
    "            \"Pred_Vol\": self.pred_sum\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9c9d4a",
   "metadata": {},
   "source": [
    "#### inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66b70728",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 148\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage OM: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOM\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 148\u001b[0m     \u001b[43mevaluate_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 26\u001b[0m, in \u001b[0;36mevaluate_all\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mevaluate_all\u001b[39m():\n\u001b[0;32m---> 26\u001b[0m     cfg \u001b[38;5;241m=\u001b[39m \u001b[43mConfig\u001b[49m()\n\u001b[1;32m     27\u001b[0m     device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(cfg\u001b[38;5;241m.\u001b[39mDEVICE \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m# 1. 載入模型\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Config' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "\n",
    "def save_prediction_image(pred, gt, img, save_path):\n",
    "    \"\"\"\n",
    "    畫出 Input, GT, Pred 的對比圖 (參考學長的 plot_result)\n",
    "    \"\"\"\n",
    "    # 轉回 0~255\n",
    "    img = (img * 255).astype(np.uint8)\n",
    "    gt = (gt * 255).astype(np.uint8)\n",
    "    pred = (pred * 255).astype(np.uint8)\n",
    "    \n",
    "    # 簡單拼接: [Input, GT, Pred]\n",
    "    # 你可以依照需求改成疊圖 (Overlay)\n",
    "    concat = np.hstack([img, gt, pred])\n",
    "    cv2.imwrite(save_path, concat)\n",
    "\n",
    "def evaluate_all():\n",
    "    cfg = Config()\n",
    "    device = torch.device(cfg.DEVICE if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # 1. 載入模型\n",
    "    print(\"Loading Model...\")\n",
    "    # 這裡你需要先跑一次 train.py 產生 best_model.pth\n",
    "    model_path = os.path.join(cfg.CHECKPOINT_DIR, \"best_model.pth\")\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Model not found at {model_path}! Please train first.\")\n",
    "        return\n",
    "\n",
    "    # 計算 Input Channels (需與 Training 一致)\n",
    "    # 這裡簡單假設你沒開 grad/blur，若是 config 有開要同步邏輯\n",
    "    dummy_ds = CRNNDataset(cfg.TRAIN_IMG_DIR, n_frames=cfg.N_FRAMES, \n",
    "                           use_blur=cfg.USE_BLUR, use_grad=cfg.USE_GRAD)\n",
    "    in_ch = dummy_ds[0]['curr'].shape[0]\n",
    "\n",
    "    model_cfg = ModelConfig(\n",
    "        block_channels=cfg.BLOCK_CHANNELS,\n",
    "        n_frames=cfg.N_FRAMES,\n",
    "        input_channels=in_ch,\n",
    "        num_classes=cfg.NUM_CLASSES\n",
    "    )\n",
    "    model = ConcurrentUNet(model_cfg).to(device)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "\n",
    "    # 2. 準備測試資料 (按 Case 處理)\n",
    "    # 假設 TEST_IMG_DIR 下面是各個 Case 的資料夾\n",
    "    test_root = './data/all/test'          # 請修改為實際路徑\n",
    "    test_target = './data/all/test_target' # 請修改為實際路徑\n",
    "    output_dir = './evaluation_results'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # 取得所有 Case 名稱\n",
    "    case_names = sorted([d for d in os.listdir(test_root) \n",
    "                        if os.path.isdir(os.path.join(test_root, d))])\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    print(f\"Found {len(case_names)} cases to evaluate.\")\n",
    "\n",
    "    # 3. 逐一 Case 評估\n",
    "    for case_name in tqdm(case_names, desc=\"Evaluating Cases\"):\n",
    "        case_img_dir = os.path.join(test_root, case_name)\n",
    "        case_target_dir = os.path.join(test_target, case_name) # 假設結構對稱\n",
    "        \n",
    "        # 針對單一 Case 建立 Dataset\n",
    "        # 注意：這裡 root_dir 直接指到 case 資料夾，所以 Dataset 內部的邏輯要能處理\n",
    "        # 我們之前寫的 Dataset 預設 root_dir 下面是 case folders\n",
    "        # 為了方便，我們這裡還是指向 root，但在 Dataset 內部我們只會讀取特定 case\n",
    "        # 或者：簡單一點，我們直接修改 Dataset 讓它接受 list of files\n",
    "        # 這裡採用最簡單方法：直接用我們寫好的 Dataset，但 root 指向 case 的上一層，\n",
    "        # 然後用 dataset 內部的 filter? 不，這樣太慢。\n",
    "        \n",
    "        # --- 權宜之計：直接在這裡實例化 Dataset 讀取單一資料夾 ---\n",
    "        # 為了不改動 Dataset.py 太大，建議 Dataset 支援 \"Single Case Mode\"\n",
    "        # 只要傳入 case_img_dir 當作 root，且 Dataset 發現下面沒有子資料夾時，就會把它當作單一 case 處理\n",
    "        # (我之前給你的 Dataset 已經包含了這個邏輯 check: if not case_dirs...)\n",
    "        \n",
    "        ds = CRNNDataset(\n",
    "            root_dir=case_img_dir, \n",
    "            target_dir=case_target_dir,\n",
    "            n_frames=cfg.N_FRAMES,\n",
    "            use_blur=cfg.USE_BLUR,\n",
    "            use_grad=cfg.USE_GRAD\n",
    "        )\n",
    "        \n",
    "        loader = DataLoader(ds, batch_size=cfg.BATCH_SIZE, shuffle=False) # 絕對不能 Shuffle\n",
    "        \n",
    "        metrics = VolumeMetrics()\n",
    "        \n",
    "        # 建立保存圖片的資料夾\n",
    "        save_img_dir = os.path.join(output_dir, \"plots\", case_name)\n",
    "        os.makedirs(save_img_dir, exist_ok=True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(loader):\n",
    "                x_prev = batch['prev'].to(device)\n",
    "                x_curr = batch['curr'].to(device)\n",
    "                x_next = batch['next'].to(device) if 'next' in batch else None\n",
    "                y_true = batch['label'].to(device)\n",
    "\n",
    "                # Inference\n",
    "                logits = model(x_prev, x_curr, x_next)\n",
    "                preds = torch.sigmoid(logits)\n",
    "                preds_bin = (preds > 0.5).float() # 二值化\n",
    "\n",
    "                # 更新指標\n",
    "                metrics.update(preds_bin, y_true)\n",
    "\n",
    "                # 保存圖片 (只存每個 Batch 的第一張示意，避免存太多)\n",
    "                # 這裡需要小心 tensor 轉 numpy 的維度\n",
    "                # batch['curr'] 是 (B, C, H, W)，我們只取 Channel 0 (原圖)\n",
    "                input_img = batch['curr'][0, 0].cpu().numpy() \n",
    "                gt_img = y_true[0, 0].cpu().numpy()\n",
    "                pred_img = preds_bin[0, 0].cpu().numpy()\n",
    "                \n",
    "                # 存檔名包含 Batch Index\n",
    "                save_path = os.path.join(save_img_dir, f\"slice_{i*cfg.BATCH_SIZE}.png\")\n",
    "                save_prediction_image(pred_img, gt_img, input_img, save_path)\n",
    "\n",
    "        # 計算該 Case 的最終分數\n",
    "        res = metrics.get_metrics()\n",
    "        res['Case'] = case_name\n",
    "        all_results.append(res)\n",
    "        \n",
    "        # 顯示當前 Case 的 OM\n",
    "        # tqdm.write(f\"Case {case_name}: OM={res['OM']:.4f}\")\n",
    "\n",
    "    # 4. 輸出報表\n",
    "    df = pd.DataFrame(all_results)\n",
    "    # 把 Case 移到第一欄\n",
    "    cols = ['Case'] + [c for c in df.columns if c != 'Case']\n",
    "    df = df[cols]\n",
    "    \n",
    "    csv_path = os.path.join(output_dir, \"case_result.csv\")\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"\\nEvaluation Complete! Results saved to {csv_path}\")\n",
    "    print(f\"Average OM: {df['OM'].mean():.4f}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    evaluate_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d527b2",
   "metadata": {},
   "source": [
    "#### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29f6f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "# 匯入專案模組\n",
    "from config import Config\n",
    "from dataset import CRNNDataset\n",
    "from model import ConcurrentUNet, ModelConfig\n",
    "from loss import WeightedConsecutiveLoss\n",
    "from utils import calculate_metrics\n",
    "\n",
    "def train():\n",
    "    # --- 1. 初始化與配置 ---\n",
    "    cfg = Config()\n",
    "    \n",
    "    # 建立存檔目錄\n",
    "    save_dir = cfg.CHECKPOINT_DIR\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # 記錄檔 (對應學長的 logs.json)\n",
    "    log_file = os.path.join(save_dir, 'training_log.json')\n",
    "    \n",
    "    device = torch.device(cfg.DEVICE if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Start Training on {device}...\")\n",
    "\n",
    "    # --- 2. 資料準備 ---\n",
    "    # 這裡我們將資料集切分為 Train (80%) 和 Validation (20%)\n",
    "    # 學長是用 split_num 手動切，這裡用 PyTorch 標準做法\n",
    "    full_ds = CRNNDataset(\n",
    "        root_dir=cfg.TRAIN_IMG_DIR,\n",
    "        target_dir=cfg.TRAIN_MASK_DIR,\n",
    "        n_frames=cfg.N_FRAMES,\n",
    "        use_blur=cfg.USE_BLUR,\n",
    "        use_grad=cfg.USE_GRAD\n",
    "    )\n",
    "    \n",
    "    # 自動偵測 channel 數\n",
    "    sample_ch = full_ds[0]['curr'].shape[0]\n",
    "    print(f\"Detected Input Channels: {sample_ch}\")\n",
    "    \n",
    "    val_size = int(len(full_ds) * 0.2)\n",
    "    train_size = len(full_ds) - val_size\n",
    "    train_ds, val_ds = random_split(full_ds, [train_size, val_size])\n",
    "    \n",
    "    print(f\"Data Split: Train={len(train_ds)}, Val={len(val_ds)}\")\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=cfg.BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=cfg.BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    # --- 3. 模型與優化器 ---\n",
    "    model_cfg = ModelConfig(\n",
    "        block_channels=cfg.BLOCK_CHANNELS,\n",
    "        dropout_rate=cfg.DROPOUT_RATE,\n",
    "        n_frames=cfg.N_FRAMES,\n",
    "        input_channels=sample_ch,\n",
    "        num_classes=cfg.NUM_CLASSES\n",
    "    )\n",
    "    model = ConcurrentUNet(model_cfg).to(device)\n",
    "\n",
    "    criterion = WeightedConsecutiveLoss(loss_ratio=0.5, consecutive=cfg.N_FRAMES).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=cfg.LEARNING_RATE)\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    # --- 4. 監控變數 (還原學長的 Checkpoint 邏輯) ---\n",
    "    best_metrics = {\n",
    "        'val_loss': float('inf'), # Min\n",
    "        'val_om': float('-inf'),  # Max\n",
    "        'train_loss': float('inf'),\n",
    "        'train_om': float('-inf')\n",
    "    }\n",
    "    \n",
    "    # --- 5. 訓練迴圈 ---\n",
    "    for epoch in range(cfg.EPOCHS):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # === Training Phase ===\n",
    "        model.train()\n",
    "        train_log = {'loss': 0, 'dice': 0, 'om': 0, 'acc': 0}\n",
    "        \n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{cfg.EPOCHS} [Train]\")\n",
    "        for batch in pbar:\n",
    "            # 搬運資料\n",
    "            x_prev = batch['prev'].to(device)\n",
    "            x_curr = batch['curr'].to(device)\n",
    "            x_next = batch['next'].to(device) if 'next' in batch else None\n",
    "            y_true = batch['label'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward (Mixed Precision)\n",
    "            with torch.cuda.amp.autocast():\n",
    "                logits = model(x_prev, x_curr, x_next)\n",
    "                loss = criterion(y_true, torch.sigmoid(logits)) # Loss 內部通常預期 0~1 的 input\n",
    "            \n",
    "            # Backward\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            # 計算指標\n",
    "            metrics = calculate_metrics(logits, y_true)\n",
    "            \n",
    "            # 更新 Log\n",
    "            train_log['loss'] += loss.item()\n",
    "            train_log['dice'] += metrics['dice']\n",
    "            train_log['om'] += metrics['om']\n",
    "            train_log['acc'] += metrics['acc']\n",
    "            \n",
    "            pbar.set_postfix({'loss': loss.item(), 'om': metrics['om']})\n",
    "\n",
    "        # 平均化 Train Metrics\n",
    "        for k in train_log: train_log[k] /= len(train_loader)\n",
    "\n",
    "        # === Validation Phase ===\n",
    "        model.eval()\n",
    "        val_log = {'loss': 0, 'dice': 0, 'om': 0, 'acc': 0}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                x_prev = batch['prev'].to(device)\n",
    "                x_curr = batch['curr'].to(device)\n",
    "                x_next = batch['next'].to(device) if 'next' in batch else None\n",
    "                y_true = batch['label'].to(device)\n",
    "\n",
    "                logits = model(x_prev, x_curr, x_next)\n",
    "                loss = criterion(y_true, torch.sigmoid(logits))\n",
    "                \n",
    "                metrics = calculate_metrics(logits, y_true)\n",
    "                \n",
    "                val_log['loss'] += loss.item()\n",
    "                val_log['dice'] += metrics['dice']\n",
    "                val_log['om'] += metrics['om']\n",
    "                val_log['acc'] += metrics['acc']\n",
    "        \n",
    "        # 平均化 Val Metrics\n",
    "        for k in val_log: val_log[k] /= len(val_loader)\n",
    "\n",
    "        # === 結算與存檔 (還原學長的 4 個 Checkpoint) ===\n",
    "        epoch_time = time.time() - start_time\n",
    "        print(f\"\\nSummary Ep {epoch+1} | Time: {epoch_time:.1f}s\")\n",
    "        print(f\"Train | Loss: {train_log['loss']:.4f} | OM: {train_log['om']:.4f} | Dice: {train_log['dice']:.4f}\")\n",
    "        print(f\"Val   | Loss: {val_log['loss']:.4f} | OM: {val_log['om']:.4f} | Dice: {val_log['dice']:.4f}\")\n",
    "\n",
    "        # 1. Save Best Val Loss (model_loss.h5)\n",
    "        if val_log['loss'] < best_metrics['val_loss']:\n",
    "            best_metrics['val_loss'] = val_log['loss']\n",
    "            torch.save(model.state_dict(), os.path.join(save_dir, 'best_val_loss.pth'))\n",
    "            print(\"✅ Saved Best Val Loss Model\")\n",
    "\n",
    "        # 2. Save Best Val OM (model_om.h5)\n",
    "        if val_log['om'] > best_metrics['val_om']:\n",
    "            best_metrics['val_om'] = val_log['om']\n",
    "            torch.save(model.state_dict(), os.path.join(save_dir, 'best_val_om.pth'))\n",
    "            print(\"✅ Saved Best Val OM Model\")\n",
    "\n",
    "        # 3. Save Best Train Loss (model_train_loss.h5) - 選用\n",
    "        if train_log['loss'] < best_metrics['train_loss']:\n",
    "            best_metrics['train_loss'] = train_log['loss']\n",
    "            # torch.save(model.state_dict(), os.path.join(save_dir, 'best_train_loss.pth'))\n",
    "\n",
    "        # 4. Save Best Train OM (model_train_om.h5) - 選用\n",
    "        if train_log['om'] > best_metrics['train_om']:\n",
    "            best_metrics['train_om'] = train_log['om']\n",
    "            # torch.save(model.state_dict(), os.path.join(save_dir, 'best_train_om.pth'))\n",
    "\n",
    "        # 寫入 JSON Log\n",
    "        log_entry = {\n",
    "            'epoch': epoch + 1,\n",
    "            'time': epoch_time,\n",
    "            'train': train_log,\n",
    "            'val': val_log\n",
    "        }\n",
    "        with open(log_file, 'a') as f:\n",
    "            f.write(json.dumps(log_entry) + \"\\n\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
